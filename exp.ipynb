{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import tinycudann as tcnn\n",
    "import json\n",
    "\n",
    "### Pay Attention to:\n",
    "# 1. The hidden layers of MLP and TCNN are different (MLP has one more hidden layer than TCNN)\n",
    "# 2. TCNN mlp has no bias\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dims, hidden_dims, out_dims, hidden_layers):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dims, hidden_dims, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(hidden_dims, hidden_dims, bias=False),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dims, out_dims, bias=False)\n",
    "        )\n",
    "        \n",
    "        # randomly init the weights and bias\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                # nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class TCNN(nn.Module):\n",
    "    def __init__(self, in_dims, hidden_dims, out_dims, hidden_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = tcnn.Network(\n",
    "            n_input_dims=in_dims,\n",
    "            n_output_dims=out_dims,\n",
    "            network_config={\n",
    "                \"otype\": \"CutlassMLP\",\n",
    "                \"activation\": \"ReLU\",\n",
    "                \"output_activation\": \"None\",\n",
    "                \"n_neurons\": hidden_dims,\n",
    "                \"n_hidden_layers\": hidden_layers + 1,\n",
    "            },\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mlp_as_tcnn_json(mlp_model, save_path, hidden_dims, out_dims, dims_multiplier=16):\n",
    "    mlp_model_keys = mlp_model.state_dict().keys()\n",
    "\n",
    "    weights = []\n",
    "    for key in mlp_model_keys:\n",
    "        weights.append(mlp_model.state_dict()[key].cpu().numpy().flatten())\n",
    "\n",
    "    # padding the last layer output dims to 32\n",
    "    padded_dims = (out_dims // dims_multiplier + 1) * dims_multiplier\n",
    "    weights[-1] = np.pad(weights[-1], (0, hidden_dims*padded_dims - weights[-1].flatten().shape[0]), 'constant', constant_values=0)\n",
    "\n",
    "    # concatenate the weights\n",
    "    weights = np.concatenate(weights)\n",
    "\n",
    "    # save the weights to json\n",
    "    json_weights = {}\n",
    "    params_type = 'float'\n",
    "    params_binary = {}\n",
    "    \n",
    "    bytes = weights.astype(np.float32).tobytes()\n",
    "    params_binary['bytes'] = [byte for byte in bytes]\n",
    "    params_binary['subtype'] = None\n",
    "    \n",
    "    json_weights['n_params'] = weights.shape[0]\n",
    "    json_weights['params_type'] = params_type\n",
    "    json_weights['params_binary'] = params_binary\n",
    "    \n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(json_weights, f)\n",
    "    \n",
    "        \n",
    "def tcnn_read_json(json_path, tcnn_model):\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_weights = json.load(f)\n",
    "    \n",
    "    params_binary = json_weights['params_binary']['bytes']\n",
    "    params_fp32 = np.frombuffer(bytes(params_binary), dtype=np.float32)\n",
    "    \n",
    "    # load the weights to tcnn model\n",
    "    checkpoint = {\n",
    "        'net.params': torch.from_numpy(params_fp32)\n",
    "    }\n",
    "    \n",
    "    # load the weights to tcnn model\n",
    "    # pay attention that tcnn_model is in device or host\n",
    "    tcnn_model.load_state_dict(checkpoint)\n",
    "    \n",
    "    return tcnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dims = 32\n",
    "hidden_dims = 64\n",
    "out_dims = 25\n",
    "hidden_layers = 3\n",
    "\n",
    "save_path = \"tcnn_mlp.json\"\n",
    "\n",
    "mlp_model = MLP(in_dims, hidden_dims, out_dims, hidden_layers)\n",
    "tcnn_model = TCNN(in_dims, hidden_dims, out_dims, hidden_layers)\n",
    "\n",
    "# test the tcnn model\n",
    "x = torch.randn(1, 32)\n",
    "mlp_output = mlp_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP output:  tensor([[ 1.0674, -0.8858, -1.5892, -3.3803,  1.0649,  0.7968, -2.2129,  2.9356,\n",
      "         -0.9036, -0.5457,  0.5316, -0.2651, -0.8903, -2.4988, -1.2052,  0.9512,\n",
      "         -2.3698,  0.4381,  2.8194, -0.5864,  0.3877, -3.1824,  0.7544,  0.2227,\n",
      "          0.8431]], grad_fn=<MmBackward0>)\n",
      "TCNN output:  tensor([[ 1.0674, -0.8853, -1.5889, -3.3848,  1.0635,  0.7949, -2.2109,  2.9336,\n",
      "         -0.9023, -0.5498,  0.5303, -0.2610, -0.8872, -2.4961, -1.2061,  0.9531,\n",
      "         -2.3711,  0.4392,  2.8164, -0.5869,  0.3862, -3.1797,  0.7495,  0.2219,\n",
      "          0.8472]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yijie Deng\\AppData\\Local\\Temp\\ipykernel_16136\\3818351087.py:41: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  'net.params': torch.from_numpy(params_fp32)\n",
      "e:\\anaconda3\\envs\\main\\lib\\site-packages\\tinycudann\\modules.py:178: UserWarning: input must be a CUDA tensor, but isn't. This indicates suboptimal performance.\n",
      "  warnings.warn(\"input must be a CUDA tensor, but isn't. This indicates suboptimal performance.\")\n"
     ]
    }
   ],
   "source": [
    "save_mlp_as_tcnn_json(mlp_model, save_path, hidden_dims, out_dims)\n",
    "tcnn_read_json(save_path, tcnn_model)\n",
    "\n",
    "tcnn_output = tcnn_model(x)\n",
    "\n",
    "print(\"MLP output: \", mlp_output)\n",
    "print(\"TCNN output: \", tcnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP output:  tensor([[ 1.0674, -0.8858, -1.5892, -3.3803,  1.0649,  0.7968, -2.2129,  2.9356,\n",
      "         -0.9036, -0.5457,  0.5316, -0.2651, -0.8903, -2.4988, -1.2052,  0.9512,\n",
      "         -2.3698,  0.4381,  2.8194, -0.5864,  0.3877, -3.1824,  0.7544,  0.2227,\n",
      "          0.8431]], grad_fn=<MmBackward0>)\n",
      "TCNN output:  tensor([[ 1.0674, -0.8853, -1.5889, -3.3848,  1.0635,  0.7949, -2.2109,  2.9336,\n",
      "         -0.9023, -0.5498,  0.5303, -0.2610, -0.8872, -2.4961, -1.2061,  0.9531,\n",
      "         -2.3711,  0.4392,  2.8164, -0.5869,  0.3862, -3.1797,  0.7495,  0.2219,\n",
      "          0.8472]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "save_mlp_as_tcnn_json(mlp_model, save_path, hidden_dims, out_dims)\n",
    "tcnn_read_json(save_path, tcnn_model)\n",
    "\n",
    "tcnn_output = tcnn_model(x)\n",
    "\n",
    "print(\"MLP output: \", mlp_output)\n",
    "print(\"TCNN output: \", tcnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 64 + 64 * 64 * 2 + 64 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
